# -*- coding: utf-8 -*-
"""Spotify_music_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HFt4lP7oE7B64L7gEVnrJW97ijFG0GyH
"""

import warnings
warnings.filterwarnings("ignore")
import pandas as pd
df=pd.read_csv("/content/data (3).csv")
df

#import dependencies
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.decomposition import PCA
import seaborn as sns

df.isna().sum()

df.dtypes

df.corr()

#removing the less correlated attributes
df.drop(columns=["Unnamed: 0","energy","key","liveness","loudness","mode","tempo","time_signature"],axis=1,inplace=True)

df

#convert the strings to numerical values using label encoder
le=LabelEncoder()
df["song_title"]=le.fit_transform(df["song_title"])
df["artist"]=le.fit_transform(df["artist"])
df

#seperate attributes and class label
X=df.drop(columns=["target"],axis=1)
y=df["target"]

X

y

#using Minmaxscaler to allocate all the values within a certain range
mm=MinMaxScaler()
mm.fit(X)
X_scaled=mm.transform(X)
X_scaled

X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.3,random_state=1)

#graphs showing relations:
import matplotlib.pyplot as plt
y=df['target'].value_counts()
plt.figure(figsize=(5,5))
labels=["loves songs","Doesnt love songs"]
plt.pie(y,labels=labels)
plt.legend(loc='lower left')
plt.title('Target')
plt.show()

sns.countplot(x='song_title',data=df)

#applying algorithms
knn=KNeighborsClassifier()
svm=SVC()
gn=GaussianNB()
mn=MultinomialNB()
dc=DecisionTreeClassifier()
rf=RandomForestClassifier()
ab=AdaBoostClassifier()
models=[knn,svm,gn,mn,dc,rf,ab]
for model in models:
  print('*'*25,model,'*'*25)
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred))
  print(ConfusionMatrixDisplay.from_predictions(y_test,y_pred))

#as accuracy is very low we try performing oversampling and undersampling
y_train.value_counts()

#oversampling
sm=SMOTE()
X_train_sm,y_train_sm=sm.fit_resample(X_train,y_train)

y_train_sm.value_counts()

knsm=KNeighborsClassifier()
svsm=SVC()
nbsm=GaussianNB()
mnsm=MultinomialNB()
dtsm=DecisionTreeClassifier()
rfsm=RandomForestClassifier(random_state=1)
absm=AdaBoostClassifier()
models1=[knsm,svsm,nbsm,mnsm,dtsm,rfsm,absm]
for model in models1:
  print('*'*25,model,'*'*25)
  model.fit(X_train_sm,y_train_sm)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred))
  print(ConfusionMatrixDisplay.from_predictions(y_test,y_pred))

#undersampling
us=RandomUnderSampler(random_state=1)
X_train_us,y_train_us=us.fit_resample(X_train,y_train)

y_train_us.value_counts()

knus=KNeighborsClassifier()
svus=SVC()
nbus=GaussianNB()
mnus=MultinomialNB()
dtus=DecisionTreeClassifier()
rfus=RandomForestClassifier(random_state=1)
abus=AdaBoostClassifier()
models2=[knus,svus,nbus,mnus,dtus,rfus,abus]
for model in models2:
  print('*'*25,model,'*'*25)
  model.fit(X_train_us,y_train_us)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred))
  print(ConfusionMatrixDisplay.from_predictions(y_test,y_pred))

#PCA
pca=PCA()
X_train_pca=pca.fit_transform(X_train)
X_test_pca=pca.transform(X_test)

knpca=KNeighborsClassifier()
svpca=SVC()
nbpca=GaussianNB()
dtpca=DecisionTreeClassifier()
rfpca=RandomForestClassifier(random_state=1)
abpca=AdaBoostClassifier()
models3=[knpca,svpca,nbpca,dtpca,rfpca,abpca]
for model in models3:
  print('*'*25,model,'*'*25)
  model.fit(X_train_pca,y_train)
  y_pred=model.predict(X_test_pca)
  print(classification_report(y_test,y_pred))
  print(ConfusionMatrixDisplay.from_predictions(y_test,y_pred))

